{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking on foil data part 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load imports.py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas\n",
    "import scipy as sp\n",
    "import scipy.ndimage as snd\n",
    "import scipy.signal as ss\n",
    "import mkl_fft\n",
    "import fast_histogram\n",
    "import sys, os, datetime, shutil, glob, itertools, collections\n",
    "import h5py\n",
    "#from tqdm.notebook import trange, tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tqdm.notebook as tqdm\n",
    "import skimage.morphology as skm\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,7)\n",
    "filenames=glob.glob('/UserData/gorkhover/TAIS2020/foils/p1/new2/*.h5')\n",
    "firstrun=[h5py.File(f,'r')['meta/runs'][0] for f in filenames]\n",
    "filenames=[x for _,x in sorted(zip(firstrun,filenames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create result dirs\n",
    "from pathlib import Path\n",
    "\n",
    "for filename in filenames:\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    print(name)\n",
    "    Path(f\"/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in filenames:\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    f=h5py.File(filename,'r')\n",
    "    firstrun=f['meta/runs'][0].decode('ascii')\n",
    "    lastrun=f['meta/runs'][-1].decode('ascii')\n",
    "\n",
    "\n",
    "    md=np.array(f['detectors/dual/mean'][50:-50,50:-150])\n",
    "    mo=np.array(f['detectors/octal/mean'][200:-200,250:-250])\n",
    "    vd=np.square(np.array(f['detectors/dual/std'][50:-50,50:-150]))\n",
    "    vo=np.square(np.array(f['detectors/octal/std'][200:-200,250:-250]))\n",
    "    fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(20,10))\n",
    "    qd=vd/md\n",
    "    qo=vo/mo\n",
    "    im1=ax1.matshow(qd,vmin=np.nanpercentile(qd,1),vmax=np.nanpercentile(qd,99))\n",
    "    ax1.set_title(f'var/mean dual')\n",
    "    plt.colorbar(im1,ax=ax1)\n",
    "    im2=ax2.matshow(qo,vmin=np.nanpercentile(qo[200:-200,200:-200],1),vmax=np.nanpercentile(qo[200:-200,200:-200],99))\n",
    "    ax2.set_title(f'var/mean octal')\n",
    "    plt.colorbar(im2,ax=ax2)\n",
    "    fig.suptitle(f'{name}/{firstrun}-{lastrun}')\n",
    "    fig.tight_layout(rect=[0.05, 0.1, .95, 0.9])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'varmeanquotient.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## used Backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:#[filenames[0],filenames[-1]]:\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    f=h5py.File(filename,'r')\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "\n",
    "    firstrun=f['meta/runs'][0].decode('ascii')\n",
    "    lastrun=f['meta/runs'][-1].decode('ascii')\n",
    "\n",
    "    bgd=np.array(f['detectors/dual/bg'][50:-50,50:-150])\n",
    "    bgo=np.array(f['detectors/octal/bg'][200:-200,250:-250])\n",
    "    fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(20,10))\n",
    "    im1=ax1.matshow(bgd,vmin=np.percentile(bgd[bgd!=0],5),vmax=np.percentile(bgd[bgd!=0],95))\n",
    "    ax1.set_title(f'background used on dual')\n",
    "    plt.colorbar(im1,ax=ax1)\n",
    "    im2=ax2.matshow(bgo,vmin=np.percentile(bgo[bgo!=0],5),vmax=np.percentile(bgo[bgo!=0],95))\n",
    "    ax2.set_title(f'background used on octal')\n",
    "    plt.colorbar(im2,ax=ax2)\n",
    "    fig.suptitle(f'{name}/{firstrun}-{lastrun}')\n",
    "    fig.tight_layout(rect=[0.05, 0.1, .95, 0.9])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'bg.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean images ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    f=h5py.File(filename,'r')\n",
    "    firstrun=f['meta/runs'][0].decode('ascii')\n",
    "    lastrun=f['meta/runs'][-1].decode('ascii')\n",
    "    md=np.array(f['detectors/dual/mean'][50:-50,50:-150])\n",
    "    mo=np.array(f['detectors/octal/mean'][200:-200,250:-250])\n",
    "    sd=np.array(f['detectors/dual/std'][50:-50,50:-150])\n",
    "    so=np.array(f['detectors/octal/std'][200:-200,250:-250])\n",
    "    fig,((ax1,ax2),(ax3,ax4))=plt.subplots(ncols=2,nrows=2,figsize=(20,20))\n",
    "    im1=ax1.matshow(md,vmin=np.mean(md[md!=0])*0.8,vmax=np.mean(md[md!=0])*1.2)\n",
    "    ax1.set_title(f'mean dual')\n",
    "    plt.colorbar(im1,ax=ax1)\n",
    "    im2=ax2.matshow(mo,vmin=np.mean(mo[mo!=0])*0.8,vmax=np.mean(mo[mo!=0])*1.2)#,vmin=np.percentile(mo,10),vmax=np.percentile(mo,99))\n",
    "    ax2.set_title(f'mean octal')\n",
    "    plt.colorbar(im2,ax=ax2)\n",
    "    im3=ax3.matshow(sd,vmin=np.mean(sd[md!=0])*0.8,vmax=np.mean(sd[md!=0])*1.2)\n",
    "    ax3.set_title(f'std dual')\n",
    "    plt.colorbar(im3,ax=ax3)\n",
    "    im4=ax4.matshow(so,vmin=np.mean(so[mo!=0])*0.8,vmax=np.mean(so[mo!=0])*1.2)#,vmin=np.percentile(mo,10),vmax=np.percentile(mo,99))\n",
    "    ax4.set_title(f'std octal')\n",
    "    plt.colorbar(im4,ax=ax4)\n",
    "    fig.suptitle(f'{name}/{firstrun}-{lastrun}')\n",
    "    fig.tight_layout(rect=[0.05, 0.05, .95, 0.95])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'meanstd_ev.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm.tqdm(filenames):\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    f=h5py.File(filename,'r')\n",
    "    shots=np.sum(f['meta/filtering/shot_ok'],axis=1)\n",
    "    labels=[s.decode('ascii') for s in f['meta/runs'][shots>0] ]\n",
    "    shots=shots[shots>0]\n",
    "    hist_d=(np.array(f['detectors/dual/hist/run'])/shots[:,None]).T\n",
    "    hist_o=(np.array(f['detectors/octal/hist/run'])/shots[:,None]).T\n",
    "    bins=f['detectors/dual/hist/bincenters']\n",
    "    kalpha=int(np.array(f['meta/Kalpha']))\n",
    "    fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(20,10))\n",
    "    ax1.semilogy(bins,hist_d)\n",
    "    ax1.set_xlim(3000,5.5*kalpha)\n",
    "    ax1.legend(labels,loc='best',ncol=2)\n",
    "    ax1.set_title(f'dual (±1500ev)')\n",
    "    for n in range(5): ax1.axvline(kalpha*n,c='green')\n",
    "    for n in range(5): ax1.axvspan(kalpha*n-1500,kalpha*n+1500,facecolor='green',alpha=0.4)\n",
    "    ax1.axvline(np.nanmean(f['photonEnergy']),c='red')\n",
    "    ax1.axvspan(np.nanmean(f['photonEnergy'])-1000,np.nanmean(f['photonEnergy'])+1000,facecolor='red',alpha=0.4)\n",
    "\n",
    "    ax2.semilogy(bins,hist_o)\n",
    "    ax2.set_xlim(-1000,5.5*kalpha)\n",
    "    ax2.set_title(f'octal (±1500ev)')\n",
    "    for n in range(6): ax2.axvline(kalpha*n,c='green')\n",
    "    for n in range(6): ax2.axvspan(kalpha*n-1500,kalpha*n+1500,facecolor='green',alpha=0.4)\n",
    "    ax2.axvspan(np.nanmean(f['photonEnergy'])-1000,np.nanmean(f['photonEnergy'])+1000,facecolor='red',alpha=0.4)\n",
    "\n",
    "    ax2.axvline(np.nanmean(f['photonEnergy']),c='red')\n",
    "    ax2.legend(labels,loc='best',ncol=2)\n",
    "    fig.suptitle(f'{name}')\n",
    "    fig.tight_layout(rect=[0.05, 0.05, .95, 0.95])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'spectrum.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm.tqdm(filenames):\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    \n",
    "    f=h5py.File(filename,'r')\n",
    "\n",
    "    samplez=np.array(f['motors/sampleZ'])+np.array(f['motors/profZ'])\n",
    "    samplex=np.array(f['motors/sampleX'])\n",
    "\n",
    "    intensity=np.array(f['detectors/dual/intensity'])\n",
    "    fig,(ax1,ax2,ax3)=plt.subplots(nrows=1,ncols=3,figsize=(27,8))\n",
    "    im1=ax1.scatter(samplex,samplez,c=intensity,s=2)#,vmin=np.percentile(p6[beamok]/beam[beamok],5),vmax=np.percentile(p6[beamok]/beam[beamok],95))\n",
    "    ax1.set_title('intensity dual')\n",
    "    ax1.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax1.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im1,ax=ax1)\n",
    "    ax2.plot(np.array(f['motors/profZ']),label='profZ')\n",
    "    \n",
    "    ax2.plot(np.array(f['motors/sampleZ']),label='sampleZ')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax3.plot(np.array(f['motors/sampleX']),label='sampleX')\n",
    "    ax3.legend(loc='upper right')\n",
    "    \n",
    "    fig.suptitle(f'{name}')\n",
    "    fig.tight_layout(rect=[0.05, 0.05, .95, 0.95])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'scanning.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## strange peak shape in 'Fe500nm_defocus+400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Fe500nm_defocus+400'\n",
    "filename=f'/UserData/gorkhover/TAIS2020/foils/p1/new2/{name}_p1.h5'\n",
    "\n",
    "    \n",
    "f=h5py.File(filename,'r')\n",
    "shots=np.sum(f['meta/filtering/shot_ok'],axis=1)\n",
    "labels=[s.decode('ascii') for s in f['meta/runs'][shots>0] ]\n",
    "shots=shots[shots>0]\n",
    "hist_d=(np.array(f['detectors/dual/hist/run'])/shots[:,None]).T\n",
    "hist_o=(np.array(f['detectors/octal/hist/run'])/shots[:,None]).T\n",
    "bins=f['detectors/dual/hist/bincenters']\n",
    "kalpha=int(np.array(f['meta/Kalpha']))\n",
    "startrun=22\n",
    "endrun=27\n",
    "\n",
    "startshot=np.cumsum(shots)[startrun]\n",
    "endshot=np.cumsum(shots)[endrun]\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2)\n",
    "ax1.semilogy(bins,hist_d[:,start:stop])\n",
    "ax1.set_xlim(4000,10000)\n",
    "ax1.legend(labels[start:stop],loc='best',ncol=2)\n",
    "ax1.set_title(f'{name} dual')\n",
    "for n in range(4): ax1.axvline(kalpha*n,c='green')\n",
    "ax1.axvline(np.nanmean(f['photonEnergy']),c='red')\n",
    "plt.show()\n",
    "#         ax2.semilogy(bins,hist_o)\n",
    "#         ax2.set_xlim(-1000,30000)\n",
    "#         ax2.set_title(f'{name} octal')\n",
    "#         for n in range(4): ax2.axvline(kalpha*n,c='green')\n",
    "#         ax2.axvline(np.nanmean(f['photonEnergy']),c='red')\n",
    "#         ax2.legend(labels,loc='best',ncol=2)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startrun=22#22\n",
    "endrun=23#27\n",
    "\n",
    "startshot=np.cumsum(shots)[startrun]\n",
    "endshot=np.cumsum(shots)[endrun]\n",
    "hists=f['detectors/dual/hist/shot'][startshot:endshot]\n",
    "print(len(hists))\n",
    "step=10\n",
    "for i in range(len(hists)//step):\n",
    "    starth=i*step\n",
    "    stoph=(i+1)*step\n",
    "    hist=np.sum(hists[starth:stoph,:],axis=0)\n",
    "    plt.semilogy(bins,hist)\n",
    "    plt.xlim(-1000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Fe500nm_defocus+400'\n",
    "filename=f'/UserData/gorkhover/TAIS2020/foils/p1/new2/{name}_p1.h5'  \n",
    "f=h5py.File(filename,'r')\n",
    "samplex=f['motors/sampleX']\n",
    "samplez=f['motors/sampleZ']\n",
    "histd=np.array(f['detectors/dual/hist/shot'])\n",
    "p8d=np.sum(histd[:,1000:1100],axis=1)\n",
    "plt.rcParams['figure.figsize']=(20,15)\n",
    "plt.scatter(samplex,samplez,c=p8d,s=4,)\n",
    "plt.xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "plt.ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## peaks vs sample position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(20,10)\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    \n",
    "    f=h5py.File(filename,'r')\n",
    "\n",
    "\n",
    "    samplex=np.array(f['motors/sampleX'])\n",
    "    samplez=np.array(f['motors/sampleZ'])+np.array(f['motors/profZ'])\n",
    "    intensity=np.array(f['detectors/dual/intensity'])\n",
    "    beam=np.array(f['pulse_energy_hutch_joule'])\n",
    "    histd=np.array(f['detectors/dual/hist/shot'])\n",
    "    p8d=np.sum(histd[:,1000:1100],axis=1)\n",
    "    p6d=np.sum(histd[:,750:850],axis=1)\n",
    "    p11d=np.sum(histd[:,1250:1350],axis=1)\n",
    "    \n",
    "    histo=np.array(f['detectors/octal/hist/shot'])\n",
    "    p8o=np.sum(histo[:,1000:1100],axis=1)\n",
    "    p6o=np.sum(histo[:,750:850],axis=1)\n",
    "    p11o=np.sum(histo[:,1250:1350],axis=1)\n",
    "    \n",
    "    norm=np.mean(beam)/beam\n",
    "    \n",
    "    fig,((ax1,ax3),(ax2,ax4),(ax5,ax6))=plt.subplots(nrows=3,ncols=2,figsize=(20,10))\n",
    "    im1=ax1.scatter(samplex,samplez,c=p6d*norm,s=2,vmin=np.mean(p6d)*0.5)\n",
    "                    #,vmin=np.percentile(p6[beamok]/beam[beamok],5),vmax=np.percentile(p6[beamok]/beam[beamok],95))\n",
    "    ax1.set_title('iron dual')\n",
    "    ax1.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax1.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im1,ax=ax1)\n",
    "\n",
    "\n",
    "    im2=ax2.scatter(samplex,samplez,c=p8d*norm,s=2,vmin=np.mean(p8d)*0.5)#,vmax=np.mean(p8d)*1.25)\n",
    "    ax2.set_title('copper dual')\n",
    "    ax2.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax2.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im2,ax=ax2)\n",
    "\n",
    "\n",
    "    im3=ax3.scatter(samplex,samplez,c=p6o*norm,s=2,vmin=np.mean(p6o)*0.5)#,vmax=np.mean(p6o)*1.25)\n",
    "    ax3.set_title('iron octal')\n",
    "    ax3.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax3.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im3,ax=ax3)\n",
    "\n",
    "\n",
    "    im4=ax4.scatter(samplex,samplez,c=p8o*norm,s=2,vmin=np.mean(p8o)*0.5)#,vmax=np.mean(p8o)*1.25)\n",
    "    ax4.set_title('copper octal')\n",
    "    ax4.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax4.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im4,ax=ax4)\n",
    "\n",
    "\n",
    "    im5=ax5.scatter(samplex,samplez,c=p11d*norm,s=2,vmin=np.mean(p11d)*0.5)#,vmax=np.mean(p11d)*1.25)\n",
    "    ax5.set_title('scatter dual')\n",
    "    ax5.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax5.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im5,ax=ax5)\n",
    "\n",
    "    im6=ax6.scatter(samplex,samplez,c=p11o*norm,s=2,vmin=np.mean(p11o)*0.5)#,vmax=np.mean(p11o)*1.25)\n",
    "    ax6.set_title('scatter octal')\n",
    "    ax6.set_xlim(np.min(samplex)-0.0005,np.max(samplex)+0.00051)\n",
    "    ax6.set_ylim(np.min(samplez)-0.00051,np.max(samplez)+0.00051)\n",
    "    plt.colorbar(im6,ax=ax6)\n",
    "    fig.suptitle(f'{name}\\n beam intensity normalised single photons hits')\n",
    "    fig.tight_layout(rect=[0.05, 0.05, .95, 0.95])\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "#     plt.show()\n",
    "#     break\n",
    "    plt.savefig(respath+'scanning_peaks.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more aggressive Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,12)\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    \n",
    "    inputfile=h5py.File(filename,'r')\n",
    "    pulse=np.array(inputfile['pulse_energy_hutch_joule'])\n",
    "    samplex=np.array(inputfile['motors/sampleX'])\n",
    "    samplez=np.array(inputfile['motors/sampleZ'])+np.array(inputfile['motors/profZ'])\n",
    "\n",
    "    pulse_ok=np.logical_and(pulse>0.00035,pulse<np.percentile(pulse,99.99))\n",
    "    samplex_ok=np.logical_and(samplex<(np.max(samplex)-0.001),samplex>np.min(samplex)+0.001)\n",
    "    shot_ok=np.logical_and(samplex_ok,pulse_ok)\n",
    "\n",
    "    for detname in ['dual','octal']:\n",
    "\n",
    "        intensity=np.array(inputfile[f'detectors/{detname}/intensity'])\n",
    "        normintensity=intensity/pulse\n",
    "        normintensity_f=normintensity[shot_ok]\n",
    "        intensity_ok=np.abs(normintensity-np.mean(normintensity_f))<3*np.std(normintensity_f)\n",
    "        detshotok=np.logical_and.reduce((intensity_ok,shot_ok))\n",
    "\n",
    "        hist=np.array(inputfile[f'detectors/{detname}/hist/shot'])[detshotok,:]\n",
    "        p8=np.sum(hist[:,1000:1100],axis=1)\n",
    "        p6=np.sum(hist[:,750:850],axis=1)\n",
    "        p11=np.sum(hist[:,1250:1350],axis=1)\n",
    "        \n",
    "        fig,((ax1,ax2),(ax3,ax4))=plt.subplots(nrows=2,ncols=2)\n",
    "        \n",
    "        im1=ax1.scatter(samplex[detshotok],samplez[detshotok],c=intensity[detshotok],s=2)\n",
    "        ax1.set_title(f'intensity {detname} after filtering')\n",
    "        plt.colorbar(im1,ax=ax1)\n",
    "\n",
    "        ax2.hist(p11)\n",
    "        ax2.set_title(f'scatter single photons {detname}')\n",
    "\n",
    "        ax3.hist(p8)\n",
    "        ax3.set_title(f'copper single photons {detname}')\n",
    "\n",
    "        ax4.hist(p6)\n",
    "        ax4.set_title(f'iron single photons {detname}')\n",
    "        plt.suptitle(f'{name} {detname}')\n",
    "        fig.tight_layout(rect=[0.05, 0.05, .95, 0.95])\n",
    "        respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "        plt.savefig(respath+f'{detname}_singlephotons_hist.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##needs p2 as input\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "o=h5py.File('/home/gorkhover/work/testp29.h5','r')\n",
    "\n",
    "fig,((ax1,ax2),(ax3,ax4))=plt.subplots(nrows=2,ncols=2)\n",
    "\n",
    "photon_evmean=np.array(o['dual/photons/mean'])\n",
    "photon_evmax=np.array(o['dual/photons/mean'])\n",
    "\n",
    "photon_evstd=np.array(o['dual/photons/std'])\n",
    "\n",
    "photon_n=np.array(o['dual/photons/n'])\n",
    "photon_evmean[photon_n==0]=np.nan\n",
    "\n",
    "mask_meandeviation=np.nan_to_num((np.abs((photon_evmean-np.nanmean(photon_evmean))/np.nanstd(photon_evmean)))<6)\n",
    "mask_meandeviation=~skm.binary_dilation(~mask_meandeviation,np.ones((9,9)))\n",
    "mask_border=~skm.binary_dilation(skm.binary_opening(photon_n==0,np.ones((5,5))),np.ones((30,30)))\n",
    "mask=np.logical_and(mask_border,mask_meandeviation)\n",
    "\n",
    "im1=ax1.matshow(photon_evmean,vmin=7000,vmax=9000)\n",
    "plt.colorbar(im1,ax=ax1)\n",
    "ax1.set_title('mean ev of single hits')\n",
    "\n",
    "im2=ax2.matshow(photon_n)\n",
    "plt.colorbar(im2,ax=ax2)\n",
    "ax2.set_title('count of single hits')\n",
    "\n",
    "im3=ax3.matshow(photon_evstd)\n",
    "plt.colorbar(im3,ax=ax3)\n",
    "ax3.set_title('std ev of single hits')\n",
    "\n",
    "ax4.matshow(mask)\n",
    "ax4.set_title('mask')\n",
    "plt.savefig('photons.png',dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(f'will keep {np.sum(mask)} of {np.sum(photon_n!=0)} pixels ({np.round(np.sum(mask)/np.sum(photon_n!=0)*100,1)}%)')\n",
    "print(f'will keep {np.sum(photon_n[mask])} of {np.sum(photon_n)} single photons ({np.round(np.sum(photon_n[mask])/np.sum(photon_n)*100,2)}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "\n",
    "outfile=h5py.File('/home/gorkhover/work/TAIS2020/foil_mask.h5','w')\n",
    "for detname in ('dual','octal'):\n",
    "    maskhigh=None \n",
    "    masklow=None\n",
    "    maskborder=None\n",
    "    for i,filename in enumerate(tqdm.tqdm(filenames)):\n",
    "        name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "        inputfile=h5py.File(filename,'r')\n",
    "        firstrun=int(inputfile['meta/runs'][0])\n",
    "        lastrun=int(inputfile['meta/runs'][-1])\n",
    "        bg='dark_foil2' if firstrun>=918639 else 'dark_foil'\n",
    "        s=np.array(inputfile[f'detectors/{detname}/std'])\n",
    "        m=np.array(inputfile[f'detectors/{detname}/mean'])\n",
    "        if maskhigh is None or masklow is None or maskborder is None:\n",
    "            maskhigh=np.zeros(m.shape,bool) \n",
    "            masklow=np.zeros(m.shape,bool) \n",
    "            maskborder=np.zeros(m.shape,bool) \n",
    "        cborder=skm.binary_opening(m<5,np.ones((5,5)))\n",
    "        cborder=skm.binary_dilation(cborder,np.ones((41,41)))\n",
    "        mm=np.copy(m)\n",
    "        sm=np.copy(s)\n",
    "        sm[cborder]=np.nan\n",
    "        mm[cborder]=np.nan\n",
    "        ts=6\n",
    "        tm=6\n",
    "        cmasks=np.logical_or(s<(np.nanmean(sm)-ts*np.nanstd(sm)), s>np.nanmean(sm)+ts*np.nanstd(sm))\n",
    "        cmaskm=np.logical_or(m<(np.nanmean(mm)-tm*np.nanstd(mm)), m>np.nanmean(mm)+tm*np.nanstd(mm))\n",
    "        maskhigh[cmasks]=1\n",
    "        maskhigh[cmaskm]=1\n",
    "        ts=3\n",
    "        tm=3\n",
    "        cmasks=np.logical_or(s<(np.nanmean(sm)-ts*np.nanstd(sm)), s>np.nanmean(sm)+ts*np.nanstd(sm))\n",
    "        cmaskm=np.logical_or(m<(np.nanmean(mm)-tm*np.nanstd(mm)), m>np.nanmean(mm)+tm*np.nanstd(mm))\n",
    "        masklow[np.logical_or(skm.binary_opening(cmaskm,np.ones((3,1))),skm.binary_opening(cmaskm,np.ones((1,3))))]=1\n",
    "        masklow[np.logical_or(skm.binary_opening(cmasks,np.ones((3,1))),skm.binary_opening(cmasks,np.ones((1,3))))]=1\n",
    "        maskborder[cborder]=1\n",
    "    mask=np.logical_or.reduce((maskhigh,masklow,maskborder))\n",
    "    mask=skm.binary_dilation(mask,np.ones((3,3)))\n",
    "    mask=skm.binary_closing(mask,np.ones((3,3)))\n",
    "    mask=~mask\n",
    "    plt.matshow(mask)\n",
    "    plt.title(f'background foils {detname}')\n",
    "    plt.savefig(f'mask_{detname}_foil.png',dpi=400)\n",
    "    plt.show()\n",
    "    outfile[f'{detname}']=mask\n",
    "outfile.close()\n",
    "#     plt.matshow(masks,vmin=0,vmax=1)\n",
    "#     plt.title(f'{name} ({i}/{firstrun}-{lastrun}/{bg}): std')\n",
    "#     plt.colorbar()\n",
    "#     #plt.savefig(f'std_{i}.png',dpi=400)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     plt.matshow(maskm,vmin=0,vmax=1)\n",
    "#     #plt.matshow(m,vmin=np.nanmean(m)-tm*np.nanstd(m),vmax=np.nanmean(m)+tm*np.nanstd(m))\n",
    "#     plt.title(f'{name} ({i}/{firstrun}-{lastrun}/{bg}): mean')\n",
    "#     plt.colorbar()\n",
    "#     #plt.savefig(f'mean_{i}.png',dpi=400)\n",
    "#     plt.show()\n",
    "#maskold=np.copy(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##needs p2 as input\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "mask=np.array(h5py.File('/home/gorkhover/work/TAIS2020/foil_mask.h5')['dual']).astype(bool)\n",
    "\n",
    "o=h5py.File('/home/gorkhover/work/testp29.h5','r')\n",
    "\n",
    "fig,((ax1,ax2),(ax3,ax4))=plt.subplots(nrows=2,ncols=2)\n",
    "\n",
    "photon_evmean=np.array(o['dual/photons/mean']).astype(float)\n",
    "photon_evstd=np.array(o['dual/photons/std']).astype(float)\n",
    "photon_n=np.array(o['dual/photons/n']).astype(float)\n",
    "\n",
    "photon_evmean[~mask]=np.nan\n",
    "photon_n[~mask]=np.nan\n",
    "photon_evstd[~mask]=np.nan\n",
    "\n",
    "im1=ax1.matshow(photon_evmean,vmin=7500,vmax=8500)\n",
    "plt.colorbar(im1,ax=ax1)\n",
    "ax1.set_title('mean ev of single hits')\n",
    "\n",
    "im2=ax2.matshow(photon_n)\n",
    "plt.colorbar(im2,ax=ax2)\n",
    "ax2.set_title('count of single hits')\n",
    "\n",
    "im3=ax3.matshow(photon_evstd)\n",
    "plt.colorbar(im3,ax=ax3)\n",
    "ax3.set_title('std ev of single hits')\n",
    "\n",
    "ax4.matshow(mask)\n",
    "ax4.set_title('mask used')\n",
    "plt.savefig('photons_masked.png',dpi=800)\n",
    "plt.show()\n",
    "\n",
    "print(f'will keep {np.sum(mask)} of {np.sum(photon_n!=0)} pixels ({np.round(np.sum(mask)/np.sum(photon_n!=0)*100,1)}%)')\n",
    "print(f'will keep {np.sum(photon_n[mask])} of {np.sum(photon_n)} single photons ({np.round(np.sum(photon_n[mask])/np.sum(photon_n)*100,2)}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beam spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamspectrum=inputfile['beamspectrum'][0:2000,400:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=ss.savgol_filter(beamspectrum,21,3)\n",
    "rms=np.sqrt(np.mean(np.square(beamspectrum-filtered),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,5)\n",
    "plt.plot(beamspectrum.T)\n",
    "plt.show()\n",
    "plt.plot(beamspectrum[:5,:].T,'*-')\n",
    "plt.show()\n",
    "plt.plot(filtered[:5,:].T)\n",
    "plt.show()\n",
    "plt.plot((beamspectrum-filtered)[:5,:].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,12)\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    \n",
    "    inputfile=h5py.File(filename,'r')\n",
    "    pulse=np.array(inputfile['pulse_energy_hutch_joule'])\n",
    "    ev=np.array(inputfile['photonEnergy'])\n",
    "    p=5\n",
    "    fig,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8))=plt.subplots(nrows=4,ncols=2)\n",
    "    pulseishigh=pulse>np.percentile(pulse,100-p)\n",
    "    pulseislow=pulse<np.percentile(pulse,p)\n",
    "    \n",
    "    bs_low=np.array(inputfile['beamspectrum'][pulseislow,340:600])\n",
    "    ids=np.argsort(pulse[pulseislow])\n",
    "    bs_low=bs_low[ids,:]\n",
    "    pulselow=pulse[pulseislow][ids]\n",
    "    ev_low=ev[pulseislow][ids]\n",
    "    \n",
    "    bs_high=np.array(inputfile['beamspectrum'][pulseishigh,340:600])\n",
    "    ids=np.argsort(pulse[pulseishigh])\n",
    "    bs_high=bs_high[ids,:]\n",
    "    pulsehigh=pulse[pulseishigh][ids]\n",
    "    ev_high=ev[pulseishigh][ids]\n",
    "\n",
    "# pulsebeam=inputfile['pulse_energy_beam_joule'][:2000]\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    for bs,ev,pulse,(axw,axbs,axdist,axmean,axrms,axev),label in zip((bs_low,bs_high),(ev_low,ev_high),(pulselow,pulsehigh),[(ax1,ax3,ax5,ax6,ax7,ax8),(ax2,ax4,ax5,ax6,ax7,ax8)],('low','high')):\n",
    "        axw.matshow(bs.T,aspect=\"auto\")\n",
    "        axw.set_title(f'{label} beamspectrum over shots')\n",
    "        axw.set_ylim(80,200)\n",
    "        axbs.plot(bs[::bs.shape[0]//10,:].T/1000,'*-')\n",
    "        axbs.set_ylim(0,140)\n",
    "        axbs.set_xlim(80,200)\n",
    "        axbs.set_title(f'{label} beamspectrum')\n",
    "        \n",
    "        filtered=ss.savgol_filter(bs,21,3)\n",
    "        rms=np.sqrt(np.nanmean(np.square(bs-filtered),axis=1))\n",
    "        axrms.hist(rms,bins=50,range=(0,15000),label=label,alpha=0.7)\n",
    "        axrms.legend()\n",
    "        axrms.set_title('rms')\n",
    "        \n",
    "        cg=np.nansum(bs*np.arange(0,bs.shape[1]),axis=1)/np.nansum(bs,axis=1)\n",
    "        axmean.hist(cg,bins=50,range=(80,200),label=label,alpha=0.7)\n",
    "        axmean.legend()\n",
    "        axmean.set_title('center')\n",
    "        \n",
    "        dist=np.nansum(bs*np.abs(np.arange(0,bs.shape[1])[None,:]-cg[:,None]),axis=1)/np.nansum(bs,axis=1)\n",
    "        axdist.hist(dist,bins=50,range=(10,40),label=label,alpha=0.7)\n",
    "        axdist.legend()\n",
    "        axdist.set_title('width')\n",
    "        \n",
    "        ev[np.isnan(ev)]=10920\n",
    "        axev.text(10915,50,'nan')\n",
    "        axev.hist(ev,bins=20,range=(10920,11040),label=label,alpha=0.7)\n",
    "        axev.legend()\n",
    "        axev.set_title('reported photon energy')\n",
    "        axev.set_xlim(11050,10900)\n",
    "    fig.suptitle(name)\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "    plt.savefig(respath+'beamspectrum.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## photon count ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accum import *\n",
    "\n",
    "\n",
    "N=500\n",
    "peaks=[\n",
    "    ['Cu',8000],\n",
    "    ['Fe',6400]\n",
    "]\n",
    "accums={}\n",
    "for detname in ['dual']:\n",
    "    for filename in tqdm.tqdm(filenames):\n",
    "        name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "        accums[name]=collections.defaultdict(accumulator)\n",
    "        inputfile=h5py.File(filename,'r')\n",
    "        det=inputfile[f'detectors/{detname}/data']\n",
    "        ranges= [(f'{p[0]}_{n}',n*p[1]-1500,n*p[1]+1500) for p,n in itertools.product(peaks,(1,2,3))]\n",
    "        ranges.extend([(f'stray_{n}',n*np.round(np.nanmean(inputfile['photonEnergy']))-1000,n*np.round(np.nanmean(inputfile['photonEnergy']))+1000) for n in (1,2,3)])\n",
    "\n",
    "        skip=int((det.shape[0]-1)/N)\n",
    "        for idet in tqdm.tqdm(range(0,N*skip,skip)):\n",
    "            if idet>=det.shape[0]-1:\n",
    "                break\n",
    "            im=np.array(det[idet,...])\n",
    "            for r in ranges:\n",
    "                mask=np.logical_and(im>r[1],im<r[2]).astype(np.float32)\n",
    "                accums[name][r[0]].add(im.astype(np.float32),mask)\n",
    "       \n",
    "        fig,ax=plt.subplots(6,3,figsize=(15,30))\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        fig.suptitle(f' {name} {detname}')\n",
    "\n",
    "        for i,(k,v) in enumerate(accums[name].items()): \n",
    "            cax=ax.flatten()[i]\n",
    "            im=cax.matshow(v.mean,vmin=ranges[i][1],vmax=ranges[i][2])\n",
    "            plt.colorbar(im,ax=cax)\n",
    "            cax.set_title(f'{k} mean')\n",
    "\n",
    "        for i,(k,v) in enumerate(accums[name].items()): \n",
    "            cax=ax.flatten()[i+9]\n",
    "            im=cax.matshow(v.n*(1000./N),vmin=0)\n",
    "            plt.colorbar(im,ax=cax)\n",
    "            cax.set_title(f'{k} n / 1000 shots')\n",
    "        respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "        plt.savefig(respath+f'photons_{detname}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intensity thresholds ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    name=os.path.splitext(os.path.basename(filename))[0][:-3]\n",
    "    fig,axs=plt.subplots(nrows=2,figsize=(15,20))\n",
    "    p1file=h5py.File(filename,'r')\n",
    "    pulsebeam=np.array(p1file['pulse_energy_beam_joule'])\n",
    "    pulsehutch=np.array(p1file['pulse_energy_beam_joule'])\n",
    "\n",
    "    photonEnergy=np.array(p1file['photonEnergy'])\n",
    "    samplex=np.array(p1file['motors']['sampleX'])\n",
    "    pulse_ok = np.logical_and(pulsebeam > 450 * 1e-6, pulsebeam < (np.mean(pulsebeam) + 3 * np.std(pulsebeam)))\n",
    "    samplex_ok = np.logical_and(samplex < (np.max(samplex) - 0.001), samplex > np.min(samplex) + 0.001)\n",
    "    energy_ok = np.abs(np.nan_to_num(photonEnergy) - np.nanmedian(photonEnergy)) < (2 * np.nanstd(photonEnergy))\n",
    "\n",
    "    shot_ok = np.logical_and.reduce((samplex_ok, pulse_ok,energy_ok))\n",
    "    \n",
    "    for detname,ax in zip(('dual','octal'),axs):\n",
    "        intensity=np.array(p1file[f'detectors/{detname}/intensity'])\n",
    "\n",
    "        intensity_f = intensity[shot_ok]/pulsehutch[shot_ok]    \n",
    "        ax.plot(np.array(intensity_f),'.',markersize=2)\n",
    "\n",
    "        intthresl=np.clip((np.mean(intensity_f)-1*np.std(intensity_f)),np.nanpercentile(intensity_f,.1),np.nanpercentile(intensity_f,5))\n",
    "        intthresh=np.clip((np.mean(intensity_f)+3*np.std(intensity_f)),np.nanpercentile(intensity_f,99.9),np.inf)\n",
    "    #     print(np.nanpercentile(intensity_f,.1),np.nanpercentile(intensity_f,5),(np.mean(intensity_f)-1*np.std(intensity_f)),intthresl)\n",
    "    #     print(np.nanpercentile(intensity_f,99.9),(np.mean(intensity_f)+4*np.std(intensity_f)),intthresh)\n",
    "    #     print(np.sum(intensity_f<intthresl),np.sum(intensity_f>intthresh))\n",
    "        ax.axhline(intthresh,color='red')\n",
    "        ax.axhline(intthresl,color='green')\n",
    "        ax.set_title(detname)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.suptitle(f'{os.path.basename(filename)[:-6]}\\n normalised intensity and thresholds')\n",
    "    respath=f'/home/gorkhover/UserDatagorkhover/TAIS2020/foils/res/{name}/'\n",
    "    plt.savefig(respath+'intensitythreshold.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoctal(data):\n",
    "    return np.concatenate((\n",
    "        data[125:1225,80:1180],\n",
    "        data[1225:-74,130:1230],\n",
    "        data[75:1175,1175:-124],\n",
    "        data[1175:-124,1230:-69]\n",
    "    ),axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
