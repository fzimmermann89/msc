{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab --no-import-all\n",
    "%matplotlib inline\n",
    "from sacla import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=log('2019 SACLA - Shotlog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run: 97, 82, 83, 84, 87, 88, 93, 94\n",
    "samples=[\n",
    "    '10 mid',\n",
    "    '10 low',\n",
    "    '51, 10 high',\n",
    "    '10 agar',\n",
    "    '51, 10 high',\n",
    "    '5 mid',\n",
    "    '20 mid'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(r):\n",
    "    runstart=int((r['Run start'][0]))\n",
    "    runend=int(r['last run'][0])\n",
    "    run=str(r.name)\n",
    "    commands=[\n",
    "        'hostname',\n",
    "        'echo $PBS_ARRAY_INDEX',\n",
    "        'cd /home/gorkhover/zimmf',\n",
    "        f'python analysis.py  /UserData/gorkhover/TAIS2019/$PBS_ARRAY_INDEX.h5 --workpath /work/gorkhover/zimmf/ --simple --run {run}'\n",
    "    ]\n",
    "    qsub(commands,run,runstart,runend)\n",
    "    print(run)\n",
    "for sample in samples:\n",
    "    runs=l.search('Sample',sample)\n",
    "    isatt=np.array(runs['Beamline filter']!='0')\n",
    "    runs=runs[isatt]\n",
    "    runs.apply(submit,axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile analysis.py\n",
    "import sacla\n",
    "import argparse, os\n",
    "import numpy as np\n",
    "import idi.reconstruction as recon\n",
    "from idi.util import *\n",
    "from funchelper import *\n",
    "import scipy.ndimage as snd\n",
    "import os, shutil\n",
    "import datetime\n",
    "\n",
    "def isdir(string):\n",
    "    if os.path.isdir(string):\n",
    "        return os.path.abspath(string)\n",
    "    else:\n",
    "        raise NotADirectoryError(string)\n",
    "\n",
    "def isfile(string):\n",
    "    if os.path.isfile(string):\n",
    "        return os.path.abspath(string)\n",
    "    else:\n",
    "        raise FileNotFoundError(string)\n",
    "\n",
    "def diffdist(*args):\n",
    "    accum = 0\n",
    "    for arg in args:\n",
    "        accum += np.diff(arg) ** 2\n",
    "    return np.sqrt(accum)\n",
    "\n",
    "def intensities(detector):\n",
    "    @asgen\n",
    "    def intensity(img):\n",
    "        return np.sum(img)\n",
    "\n",
    "    return detector.absolute_gain * 3.65 * np.array(list(intensity(detector)))\n",
    "\n",
    "def getbg(detector):\n",
    "    accum = accumulator()\n",
    "    for img in detector:\n",
    "        dat = np.array(img) * detector.absolute_gain * 3.65\n",
    "        hits = dat > 2000\n",
    "        empty = ~(snd.morphology.binary_dilation(hits, snd.morphology.generate_binary_structure(2, 2)))\n",
    "        accum.add(dat * empty.astype(float), empty)\n",
    "    return accum.mean\n",
    "\n",
    "def photonize(img, energy, gain=1, bg=0):\n",
    "    return np.rint(((np.squeeze(np.array(img)) * gain * 3.65) - bg) / energy)\n",
    "\n",
    "def photonsstats(detector, bg, energy, thres=10):\n",
    "    accum = accumulator()\n",
    "    photonsum = []\n",
    "    maxphotons = 0\n",
    "    for n, img in enumerate(detector):\n",
    "\n",
    "        photons = photonize(img, energy, detector.absolute_gain, bg)\n",
    "        ps = np.sum(photons)\n",
    "        if ps > thres:\n",
    "            accum.add(photons)\n",
    "            maxphotons = np.maximum(maxphotons, photons)\n",
    "        photonsum.append(ps)\n",
    "    return (accum.mean, accum.std, maxphotons, np.array(photonsum))\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='sacla 2019 analysis')\n",
    "parser.add_argument('inputfile', metavar='inputfile', type=isfile, help='the hdf5 inputfile to process')\n",
    "parser.add_argument('--outpath', default=None, metavar='path', type=isdir, help='where to save the output (default work dir)')\n",
    "parser.add_argument('--workpath', default=None, metavar='path', type=isdir, help='the work dir (default input file dir)')\n",
    "parser.add_argument('--run', default='', dest='run', type=str, help='run info/number to store as reference')\n",
    "parser.add_argument('--simple', dest='simple', action='store_true', help='do simple ft correlation')\n",
    "parser.add_argument('--ft3d', dest='ft3d', action='store_true', help='do 3d ft correlation')\n",
    "parser.add_argument('--direct', dest='direct', action='store_true', help='do 3d direct correlation (slow!)')\n",
    "parser.add_argument('--directrad', dest='directrad', type=int, nargs='?', default=False, const=-1, metavar='QMAX', help='do radial direct correlation')\n",
    "parser.add_argument('--detector', dest='detector', type=str, default='detector_2d_3', metavar='DETECTORNAME', help='name of detector')\n",
    "parser.add_argument('-e', dest='energy', type=float, default=6450, metavar='ENERGY in ev', help='photon energy')\n",
    "parser.add_argument('-z', dest='z', type=float, default=10, metavar='DISTANCE in cm', help='detector distance')\n",
    "parser.add_argument('--threshold', dest='photonsthreshold', type=int, default=50, metavar='THRESHOLD in photons', help='min. photons in image to keep it')\n",
    "parser.add_argument('--pixelsize', dest='pixelsize', type=float, default=0.1, metavar='PIXELSIZE in um', help='detector pixelzie')\n",
    "parser.add_argument('--maximg', dest='maximg', type=int, default=-1, metavar='MAXIMG', help='detector pixelsize')\n",
    "parser.add_argument('--allimg', dest='allimg', action='store_true', help='store all photonized images in result')\n",
    "\n",
    "args = parser.parse_args()\n",
    "if args.workpath is None:\n",
    "    args.workpath = os.path.dirname(args.inputfile)\n",
    "if args.outpath is None:\n",
    "    args.outpath = args.workpath\n",
    "workfile = os.path.join(args.workpath, os.path.basename(args.inputfile))\n",
    "if os.path.isfile(workfile):\n",
    "    print(f' File {workfile} exists, not copying to workdir.')\n",
    "else:\n",
    "    print(f' copying input to {workfile}')\n",
    "    shutil.copy(args.inputfile, workfile)\n",
    "outfile=os.path.join(args.outpath,datetime.datetime.now().strftime(f'{os.path.splitext(os.path.basename(args.inputfile))[0]}-%y%m%d-%H%M%S.npz'))\n",
    "\n",
    "run = sacla.saclarun(workfile, settings=sacla.Tais2019)\n",
    "print(f'{len(run)} images in input')\n",
    "detector = getattr(run, args.detector)\n",
    "energy = args.energy\n",
    "z = args.z * 1e-2 / args.pixelsize * 1e-6\n",
    "nmax = np.inf if args.maximg == -1 else args.maximg\n",
    "print(vars(args))\n",
    "print('init done', flush=True)\n",
    "\n",
    "# filter by distance between shots\n",
    "setdist = np.percentile(diffdist(run.sampleX), 75)\n",
    "mindist = setdist * 0.7\n",
    "distok = np.concatenate(([0], diffdist(run.sampleX, run.sampleZ))) > mindist\n",
    "shots = run[distok]\n",
    "detector = getattr(shots, args.detector)\n",
    "print(f'distance done, {len(shots)} remaining')\n",
    "\n",
    "#background\n",
    "bg = getbg(detector)\n",
    "print('background done', flush=True)\n",
    "\n",
    "#photons statistics\n",
    "meanphotons, stdphotons, maxphotons, photonsum = photonsstats(detector, bg, energy, args.photonsthreshold)\n",
    "intok = photonsum > args.photonsthreshold\n",
    "nphotonsmin = np.rint(np.percentile(photonsum[intok], 1))\n",
    "nphotonsmax = np.rint(np.percentile(photonsum[intok], 99))\n",
    "\n",
    "intok = np.logical_and.reduce((intok, nphotonsmin < photonsum, photonsum < nphotonsmax))\n",
    "mask = meanphotons > (0.1 * np.mean(meanphotons))\n",
    "shots = shots[intok]\n",
    "detector = getattr(shots, args.detector)\n",
    "print(f'found photons statistics. intensity filter done, keep >{nphotonsmin} && <{nphotonsmax}. {len(shots)} remaining')\n",
    "accum = {'simple': accumulator(), 'ft3d': accumulator(), 'direct': accumulator(), 'directrad': accumulator()}\n",
    "\n",
    "print('start recon...', flush=True)\n",
    "allimg=[]\n",
    "for n, img in enumerate(detector):\n",
    "    if n >= nmax:\n",
    "        break\n",
    "    photons = photonize(img, energy, detector.absolute_gain, bg) / meanphotons\n",
    "    photons[~mask] = 0\n",
    "    if args.allimg:\n",
    "        allimg.append(np.array(photons))\n",
    "    if args.simple:\n",
    "        accum['simple'].add(recon.simple.corr(photons))\n",
    "    if args.ft3d:\n",
    "        accum['ft3d'].add(recon.ft.corr(photons, z))\n",
    "    if args.direct:\n",
    "        accum['direct'].add(recon.direct.corr(photons, z))\n",
    "    if args.directrad:\n",
    "        accum['directrad'].add(recon.newrad.corr(photons, z, qmax))\n",
    "    if n == 0:\n",
    "        for a in accum:\n",
    "            print(a, accum[a].shape)\n",
    "    if n % 10 == 0:\n",
    "        print(n, end=' ',flush=True)\n",
    "\n",
    "allimg=np.array(allimg)\n",
    "print()\n",
    "print(f'start saving to {outfile}')\n",
    "tosave = vars(args)\n",
    "tosave.update(\n",
    "    {\n",
    "        'workfile': workfile,\n",
    "        'outfile': outfile,\n",
    "        'mask': mask,\n",
    "        'meanphotons': meanphotons,\n",
    "        'stdphotons': stdphotons,\n",
    "        'maxphotons': maxphotons,\n",
    "        'nphotonsmax': nphotonsmax,\n",
    "        'nphotonsmin': nphotonsmin,\n",
    "        'photonsum': photonsum,\n",
    "        'bg': bg,\n",
    "        'mindist': mindist,\n",
    "        'allimg':allimg\n",
    "    }\n",
    ")\n",
    "tosave.update({f'{k}_mean': v.mean for k, v in accum.items()})\n",
    "tosave.update({f'{k}_std': v.std for k, v in accum.items()})\n",
    "np.savez_compressed(outfile, **tosave)\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python analysis.py  /UserData/gorkhover/TAIS2019/782533.h5 --workpath /work/gorkhover/zimmf/ --simple --maximg 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.load('/work/gorkhover/zimmf/782533-190517-123813.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l['photonsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=l['allimg']\n",
    "c=0\n",
    "norm=recon.simple.corr((np.sum(imgs,axis=0)>0).astype(float))\n",
    "for i,img in enumerate(imgs):\n",
    "    c=c+recon.simple.corr(img)/norm\n",
    "    print(np.nanmin(c[400:600,400:600]/(i+1)),np.nanmedian(c[400:600,400:600]/(i+1)),np.nanmax(c[400:600,400:600]/(i+1)))\n",
    "r=c/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(r[400:-400,400:-400]),np.nanmin(r[400:-400,400:-400]),np.nanmax(r[400:-400,400:-400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=r-np.nanmedian(r[800:-800,400:-400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,15)\n",
    "\n",
    "plt.matshow(r[800:-800,400:-400].T,vmin=-0.005,vmax=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=l['simple_mean']\n",
    "norm=recon.simple.corr((l['mask']).astype(float))\n",
    "r=c/norm\n",
    "np.median(r[norm>1e5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab --no-import-all\n",
    "%matplotlib inline\n",
    "plt.matshow(l['simple_mean'],vmax=1e6)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idi.reconstruction as recon\n",
    "norm=recon.simple.corr(l['mask'])\n",
    "r=l['simple_mean']/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idi.util import radial_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(r[400:600,400:600],vmax=0.9,vmin=0.85)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(radial_profile(r,np.array(r.shape)//2)[2:20])\n",
    "plt.ylim([0.85,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(radial_profile(r,np.array(r.shape)//2)[2:20]l['simple_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l['maximg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
